{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Finding statistically top 5 aspect to be used as general aspects**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer type: Wikidepia/IndoT5-base\n",
      "implicit-v2\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import csv\n",
    "from pprint import pprint\n",
    "import time\n",
    "\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "\n",
    "from args import init_args\n",
    "from src.postprocess import (\n",
    "    IPostprocess,\n",
    "    EditDistancePostProcessor,\n",
    "    EmbeddingDistancePostProcessor,\n",
    ")\n",
    "from src.loader import ILoader, HotelLoader\n",
    "from src.utility import get_config, set_seed\n",
    "from src.constant import Path, ModelType, PostprocessType, ProcessType\n",
    "from src.trainer import ITrainer, T5Trainer\n",
    "from src.generator import IGenerator, T5Generator\n",
    "from src.evaluation import Evaluator\n",
    "\n",
    "from src.loader import ILoader, HotelLoader\n",
    "\n",
    "# == Dependencies Maps (Factory) ==\n",
    "trainer_config_maps = {ModelType.T5Model: T5Trainer}\n",
    "\n",
    "tokenizer_config_names = {ModelType.T5Model: T5Tokenizer}\n",
    "\n",
    "generator_config_names = {ModelType.T5Model: T5Generator}\n",
    "\n",
    "postprocess_config_names = {\n",
    "    PostprocessType.EDITDISTANCE: EditDistancePostProcessor,\n",
    "    PostprocessType.EMBEDDING: EmbeddingDistancePostProcessor,\n",
    "}\n",
    "\n",
    "\n",
    "config_path = \"resources/exp-v3/exp-m0.yaml\"\n",
    "configs = get_config(config_path)\n",
    "set_seed(configs[\"main\"][\"seed\"])\n",
    "\n",
    "mode = configs.get(\"main\").get(\"mode\")\n",
    "\n",
    "model_type = configs.get(\"type\")\n",
    "model_name = configs.get(\"main\").get(\"pretrained\")\n",
    "use_checkpoint = configs.get(\"trainer\").get(\"use_checkpoint\")\n",
    "if use_checkpoint:\n",
    "    model_name = configs.get(\"trainer\").get(\"checkpoint_path\")\n",
    "print(f\"Tokenizer type: {model_name}\")\n",
    "tokenizer = tokenizer_config_names.get(model_type).from_pretrained(model_name)\n",
    "\n",
    "# 2. Preparing Dataset ...\n",
    "loader: ILoader = HotelLoader(tokenizer, configs)\n",
    "\n",
    "train_loader, val_loader = loader.get_train_loader(), loader.get_val_loader()\n",
    "train_dataset, val_dataset = loader.get_train_dataset(), loader.get_val_dataset()\n",
    "train_sents, val_sents = train_dataset.get_sents(), val_dataset.get_sents()\n",
    "\n",
    "test_loader = loader.get_test_loader()\n",
    "test_dataset = loader.get_test_dataset()\n",
    "test_sents = test_dataset.get_sents()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_expr(labels):\n",
    "    aspects = []\n",
    "    sentiments = []\n",
    "\n",
    "    EMPTY = ''\n",
    "    def extract(sequence):\n",
    "        extractions = []\n",
    "        triplets = sequence.split(\"; \")\n",
    "        for elem in triplets:\n",
    "            elem = elem[1:-1] # Remove the in the start \"(\"  and at the end \")\".\n",
    "            try:\n",
    "                a, b, c = elem.split(', ')\n",
    "            except ValueError:\n",
    "                a, b, c = '', '', ''\n",
    "            \n",
    "            a = a.strip()\n",
    "            b = b.strip()\n",
    "            c = c.strip()\n",
    "            # Postprocess...\n",
    "            if (a == EMPTY or b == EMPTY or c == EMPTY) or (a,b,c) in extractions:\n",
    "                continue\n",
    "            extractions.append((a, b, c)) \n",
    "        return extractions\n",
    "\n",
    "    for datum in labels:\n",
    "        triplets = extract(datum)\n",
    "        for triplet in triplets:\n",
    "            aspects.append(triplet[0])\n",
    "\n",
    "    for datum in labels:\n",
    "        triplets = extract(datum)\n",
    "        for triplet in triplets:\n",
    "            sentiments.append(triplet[1])\n",
    "\n",
    "    return aspects, sentiments\n",
    "\n",
    "train_aspects, train_sentiments = get_expr(train_dataset.extracted_labels)\n",
    "test_aspects, test_sentiments = get_expr(test_dataset.extracted_labels)\n",
    "val_aspects, val_sentiments = get_expr(val_dataset.extracted_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:\n",
      " [('hotel', 824), ('kamar', 759), ('pelayanan', 339), ('kamarnya', 285), ('ac', 186), ('kamar mandi', 176), ('tempatnya', 169), ('tempat', 142), ('wifi', 121), ('harga', 121)]\n",
      "Val:\n",
      " [('hotel', 488), ('kamar', 271), ('pelayanan', 131), ('kamarnya', 85), ('kamar mandi', 50), ('tempatnya', 47), ('pelayanannya', 45), ('tempat', 44), ('fasilitas', 43), ('ac', 43)]\n"
     ]
    }
   ],
   "source": [
    "# Get Top 5 most common aspects expr as general aspect\n",
    "\n",
    "def get_n_top(collection, n):\n",
    "    from collections import Counter\n",
    "    c = Counter(collection)\n",
    "    c.most_common(n)\n",
    "    print (\"\",c.most_common(n))\n",
    "\n",
    "print(\"Train:\")\n",
    "get_n_top(train_aspects, 10)\n",
    "print(\"Val:\")\n",
    "get_n_top(val_aspects, 10)\n",
    "\n",
    "# Picked general aspect:\n",
    "# - general\n",
    "# - kamar\n",
    "# - pelayanan\n",
    "# - kamarnya\n",
    "# - tempat\n",
    "# - hotel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Checking out all aspects expresion that contains punctuation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Special character:\n",
      "!\"#$%&'()*+,-./:;<=>?@[\\]^_`{|}~\n",
      "Train:\n",
      "seprai - nya\n",
      "check - out\n",
      "air panas /\n",
      "c/o\n",
      "selimut/sprey\n",
      "toilet flash - nya\n",
      "check - in\n",
      "set - up airy\n",
      "pintu kamar - mandi\n",
      "kasur&bantalnya\n",
      "sistem check - in\n",
      "sabun /\n",
      "ac -\n",
      "ac -\n",
      "ac -\n",
      "remote - nya\n",
      "cemilan+air minum\n",
      "wi - fi\n",
      "wc - nya\n",
      "seprei/bantal\n",
      "wi - fi\n",
      "Val:\n",
      "exhaust/vacuum\n",
      "ac - nya\n",
      "pelayanan'ya\n",
      "ac - nya\n",
      "d'kmar tidur\n"
     ]
    }
   ],
   "source": [
    "def show_aspects_with_special_char(aspects,chars):\n",
    "    for aspect in aspects:\n",
    "        if any(p in aspect for p in chars):\n",
    "            print(aspect)\n",
    "\n",
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "print(\"Special character:\")\n",
    "print(punctuations)\n",
    "\n",
    "print(\"Train:\")\n",
    "show_aspects_with_special_char(train_aspects, punctuations)\n",
    "print(\"Val:\")\n",
    "show_aspects_with_special_char(val_aspects, punctuations)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "air panas/hangat\n",
      "cs /\n",
      "minum+snack gratis\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "punctuations = string.punctuation\n",
    "\n",
    "for aspect in aspects:\n",
    "    if any(p in aspect for p in punctuations):\n",
    "        print(aspect)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "57d0841d9d8ef972206d78053f97444acc7de5d086b92822aafef1aeee897422"
  },
  "kernelspec": {
   "display_name": "Python 3.9.0 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
